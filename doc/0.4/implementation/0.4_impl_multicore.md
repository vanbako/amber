# Amber 0.4 Multicore, Fabric, and Debug Implementation

Amber v0.4 scales the core into a coherent dual-core configuration with a shared victim/tag slice, interrupt fabric, and debug transport. This document tracks the implementation work for the uncore components tying those pieces together.

## Fabric Overview

- Two cores connect to a central crossbar that arbitrates accesses to:
  - The inclusive victim/tag slice (`rtl/mem/victim/victim_tag_slice.sv`).
  - Optional external memory controller (DDR/LPDDR PHY).
  - Platform peripherals (UART, timers) reused from v0.1 until refreshed.
- Each core exposes a pair of ports: a request/response channel for data + capability metadata and a sideband channel for debug/CSR traffic.
- Clocking: keep the fabric synchronous with the cores for the initial FPGA drop. Asynchronous bridges can be explored once timing margins are comfortable.

## Coherence and Ordering

- Adopt a directory-based protocol managed by the victim/tag slice. The directory tracks sharers per line and orchestrates invalidation or downgrade when capability metadata changes.
- To preserve capability semantics, tag-only updates must still flow through the directory so other cores invalidate stale metadata. Data can remain valid if bounds shrink does not violate visibility.
- The fabric must serialize loan/trace permission updates to ensure a single writer at a time. Use a token or sequencer in the slice to grant write permission.
- Define explicit ordering points: `cperm.sync` and other fences broadcast a fabric barrier message that drains outstanding transactions from the issuing core before acknowledging.

## Interrupts and Reset

- Implement a per-core interrupt concentrator that funnels external interrupts, capability faults, and debug requests into the core's CSR interface.
- Global reset should sequence: fabric -> victim/tag slice -> cores -> peripherals. Provide synchronised reset release so both cores start fetching aligned to bundle boundaries.
- For FPGA bring-up expose DIP-switch controlled reset/boot-mode pins; record mapping in this file once hardware assignments are fixed.

## Debug and Trace Infrastructure

- Debug transport rides on a lightweight CSR bus (simple address/data handshake) connecting cores, victim slice, and platform peripherals to a host bridge (UART, JTAG, or USB).
- Each core exports:
  - Commit trace FIFO with branch outcomes, capability faults, and retire causes.
  - Occupancy counters for queues (rename free list, issue queues, MSHRs).
  - Snapshot registers for capability prefix windows and checkpoint stack depth.
- The victim/tag slice reports per-core hit/miss rates, outstanding transactions, loan owner IDs, and trace permission flips.
- Plan for an optional streaming trace routed to a host over UART for early bring-up; long term the CSR bridge can expose memory-mapped trace buffers.

## Integration with Legacy Blocks

- Until refreshed, reuse the v0.1 UART (`src/0.1/rtl/periph/amber48_uart_tx.sv`) and reset synchroniser. Wrap them in thin adapters that translate between old single-core signals and the new fabric interfaces.
- Document any diverging conventions (active-low vs. active-high reset, different interrupt numbering) so downstream firmware can cope during the transition.

## Outstanding Decisions

- Choose the base fabric protocol (AXI4, TileLink, or Amber-specific). The decision affects verification collateral and reuse of existing IP. Capture pros/cons and final call here.
- Determine whether each core maintains independent branch predictor state or shares via the fabric. Shared predictors impose bandwidth requirements on the sideband channel.
- Finalise the debug bridge implementation. Candidates include a simple APB-over-UART shim or a small RISC-V debug module that already exists in partner projects.
