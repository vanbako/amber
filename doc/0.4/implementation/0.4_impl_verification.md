# Amber 0.4 Verification and Bring-Up Plan

Amber v0.4 significantly expands the core, memory system, and fabric complexity. This document tracks the verification strategy, tool flows, and bring-up milestones required to reach confidence ahead of FPGA deployment and eventual silicon.

## Verification Objectives

- Demonstrate functional correctness across the widened pipeline, capability-aware speculation, and dual-core coherency features.
- Validate the new ISA extensions (prefix windows, 128-bit atomics, loan/trace permissions) against the architectural specification.
- Achieve coverage closure on key microarchitectural behaviours: branch prediction recovery paths, LSQ hazards, capability fault handling, and fabric ordering.
- Provide a regression suite and scripting that future contributors can run locally without bespoke setup.

## Tool Flows

- **Simulation:** Extend `tools/run_verilator.sh` to support `--release 0.4`. Expected additions include:
  - Updated include paths (`src/0.4/rtl/...`).
  - New top modules (e.g., `amber40_core_tb`, `amber40_dual_tb`).
  - Generation of v0.4 binary images via the updated assembler/disassembler flow.
- **Linting:** Adopt Verible or AscentLint for continuous structural checks once the RTL tree stabilises. Capture lint waivers in `src/0.4/rtl/common/lint/`.
- **FPGA Builds:** Automate bitstream generation through scripted flows (Quartus, Vivado). Document required tool versions, environment variables, and expected resource utilisation once measured.

## Test Collateral

- **Directed Tests:** Populate `tests/0.4/asm/` with ISA-directed programs covering:
  - Prefix window transitions.
  - 128-bit LR/SC loops with contention.
  - Capability loan/trace permission manipulations.
  - Branch predictor stress (nested loops, alternating patterns).
- **Random/Constrained:** Reuse the existing Python assembler infrastructure to generate random instruction streams that honour capability semantics. Gate them behind a seed to aid reproducibility.
- **High-Level Programs:** Port the v0.3 smoke tests and microbenchmarks to exercise dual-issue decode, LSQ depth, and victim slice behaviour. Use a C harness compiled against the updated capability ABI once available.
- **Coherency Scenarios:** Build dual-core directed tests that deliberately race on capability updates, verifying that loans and bounds propagate correctly.

## Coverage Strategy

- Functional coverage points to instrument:
  - Branch predictor outcomes (taken/not taken, miss types).
  - Rename free list depletion events.
  - LSQ hazard resolutions (forwarded load, store-to-load stall, capability retry).
  - Fabric transactions (tag-only vs. data, loan updates, trace toggles).
- Structural coverage: rely on Verilator's toggle coverage initially; consider migrating to commercial tools for deeper insight if the project partners approve.
- Capture coverage reports under `build/coverage/0.4/` and add a short summary to this document with every milestone.

## Bring-Up Milestones

1. **Single-Core Simulation:** Run directed decode/execute tests through Verilator with caches stubbed out. Validate pipeline control and capability metadata flow.
2. **LSQ + Cache Integration:** Enable the memory hierarchy, execute load/store suites, and verify capability tag enforcement.
3. **Dual-Core Coherency:** Connect the fabric and victim/tag slice, run coherency-directed tests, and monitor for livelock.
4. **FPGA Prototype:** Synthesize to Arora-V 138K, hit 180 MHz timing, and execute the smoke test suite on hardware.
5. **Performance Validation:** Gather IPC, branch predictor accuracy, and cache hit rates using the debug counters; compare against design targets.

Record dates, outcomes, and issues for each milestone directly below the list as work progresses.

## Automation and CI

- Integrate regression scripts with the existing CI (GitHub Actions or internal). Each push should, at minimum, run Verilator smoke tests and lint.
- Store CI configuration under `.github/workflows/amber_0_4.yml` once created; reference it here so readers know where automation lives.
- For long-running FPGA builds, schedule nightly jobs that publish resource/timing deltas into an internal dashboard. Link to the dashboard here when available.

## Open Items

- Decide whether to gate commits on coverage thresholds in CI or rely on periodic review.
- Align on waveform dumping format (FST vs. VCD) for debugging; large dumps can stress storage if unchecked.
- Evaluate whether lightweight formal checks (e.g., capability bounds never increase without authority) provide value given the design complexity.
